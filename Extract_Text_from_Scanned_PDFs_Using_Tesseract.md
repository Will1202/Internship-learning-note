# Extract_Text_from_Scanned_PDFs_Using_Tesseract
OCRï¼šæ•™æœºå™¨ä»å›¾åƒä¸­è¯»å–æ–‡æœ¬

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæ‚¨å·²ç»ç†Ÿæ‚‰ OCRï¼ˆå…‰å­¦å­—ç¬¦è¯†åˆ«ï¼‰å°†æ–‡æœ¬å›¾åƒè½¬æ¢ä¸ºå®é™…çš„ã€å¯ç¼–è¾‘çš„æ–‡æœ¬çš„è¿‡ç¨‹ã€‚

æˆ‘ä»¬å°†ä» Tesseract å¼€å§‹æˆ‘ä»¬çš„æ—…ç¨‹ï¼ŒTesseract æ˜¯ Google å¼€å‘çš„å¼€æº OCR å¼•æ“ï¼Œç”¨äºä»æ‰«ææ–‡æ¡£ä¸­æå–æ–‡æœ¬ã€‚
## ç¬¬ 1 æ­¥ï¼šè®¾ç½®æ‚¨çš„ç¯å¢ƒ
- PyMuPDF ï¼ˆfitzï¼‰ â€“ è¯»å– PDF é¡µé¢å¹¶å°†å…¶è½¬æ¢ä¸ºå›¾åƒã€‚
- Tesseract OCR â€“ ä»æ‰«æå›¾åƒä¸­æå–æ–‡æœ¬ã€‚
- OpenCV â€“ å¸®åŠ©æ¸…ç†å›¾åƒå¹¶åœ¨æ£€æµ‹åˆ°çš„æ–‡æœ¬å‘¨å›´ç»˜åˆ¶æ¡†ã€‚
- Pillow(PIL) â€“ è®©æˆ‘ä»¬åœ¨ Colab ä¸­æ˜¾ç¤ºå’Œå¤„ç†å›¾åƒ
- NumPy â€“ å¤„ç†æ•°å­—å¹¶ä½¿å¤„ç†å›¾åƒæ›´å®¹æ˜“ã€‚

âš ï¸é‡è¦ï¼ å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ Google Colabï¼Œåˆ™å¿…é¡»æ‰‹åŠ¨å®‰è£… Tesseract OCRï¼Œå› ä¸ºé»˜è®¤æƒ…å†µä¸‹ä¸åŒ…å«å®ƒã€‚
```
!apt install -y tesseract-ocr  # Install Tesseract OCR
!pip install pymupdf pytesseract opencv-python pillow numpy  # Install required Python libraries
```
## ç¬¬ 2 æ­¥ï¼šå¯¼å…¥åº“
```
import cv2
import pytesseract
import fitz  # PyMuPDF
import numpy as np
from PIL import Image
```
## ç¬¬ 3 æ­¥ï¼šåŠ è½½æ‰«æçš„ PDF å¹¶æ‰§è¡Œç›´æ¥æå–
è®©æˆ‘ä»¬é¦–å…ˆæµ‹è¯•æˆ‘ä»¬æ˜¯å¦å¯ä»¥åœ¨æ²¡æœ‰ OCR çš„æƒ…å†µä¸‹æå–æ–‡æœ¬ã€‚å¦‚æœ PDF åŒ…å«å¯æœç´¢çš„æ–‡æœ¬ï¼Œæˆ‘ä»¬åº”è¯¥è·å¾—å¯è¯»çš„å†…å®¹ã€‚ä½†æ˜¯ï¼Œå¦‚æœ PDF åªæ˜¯ä¸€å¼ å›¾åƒï¼ˆå¦‚æ‰«æçš„æ–‡æ¡£ï¼‰ï¼Œè¿™ç§æ–¹æ³•å¯èƒ½ä¼šå¤±è´¥â€”â€”è¿™å‘æˆ‘ä»¬å±•ç¤ºäº†ä¸ºä»€ä¹ˆéœ€è¦ OCRã€‚

ä½¿ç”¨ PyMuPDF åŠ è½½ PDFï¼š é¦–å…ˆï¼Œè®©æˆ‘ä»¬æ‰“å¼€ç¤ºä¾‹æŠµæŠ¼è´·æ¬¾æ–‡æ¡£å¹¶å°è¯•åœ¨æ²¡æœ‰ OCR çš„æƒ…å†µä¸‹æå–æ–‡æœ¬ã€‚
```
# Load the scanned PDF
pdf_path = "sample_mortgage_document.pdf"  # Update this path if needed
doc = fitz.open(pdf_path)

# Extract text from the first page using a standard method (this will fail for scanned PDFs)
page = doc[0]  # Get the first page
text = page.get_text("text")  # Try extracting text

print("Extracted Text (Without OCR):")
print(text)
```
## ç¬¬ 4 æ­¥ï¼šå°† PDF é¡µé¢è½¬æ¢ä¸ºå›¾åƒ
ç”±äºæ–‡æœ¬æå–å¤±è´¥ï¼Œæˆ‘ä»¬ç°åœ¨éœ€è¦å°† PDF é¡µé¢è½¬æ¢ä¸ºå›¾åƒï¼Œç„¶åæ‰èƒ½ä½¿ç”¨ OCRã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æ­£åœ¨è½¬æ¢ PDF çš„ç¬¬ä¸€é¡µã€‚
```
# Convert the first page to an image
pix = page.get_pixmap()
img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

# Display the image
display(img)
```
ä¸ºä»€ä¹ˆè¦è½¬æ¢ä¸ºå›¾åƒï¼Ÿ
- æ‰«æçš„ PDF åŸºæœ¬ä¸Šæ˜¯æ–‡æœ¬ç…§ç‰‡ï¼Œè€Œä¸æ˜¯çœŸå®æ–‡æœ¬ã€‚
- OCRï¼ˆå…‰å­¦å­—ç¬¦è¯†åˆ«ï¼‰ä¸èƒ½ç›´æ¥ç”¨äº PDFï¼Œå®ƒéœ€è¦æ–‡æœ¬å›¾åƒã€‚
## ç¬¬ 5 æ­¥ï¼šé¢„å¤„ç†å›¾åƒä»¥æé«˜ OCR å‡†ç¡®æ€§
**ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦é¢„å¤„ç†ï¼Ÿ**

å½“æ–‡æœ¬æ¸…æ™°ä¸”å®šä¹‰æ˜ç¡®æ—¶ï¼ŒOCR æ•ˆæœæœ€ä½³ã€‚å¦‚æœå›¾åƒå˜ˆæ‚ã€æ¨¡ç³Šæˆ–å¯¹æ¯”åº¦å·®ï¼ŒOCR å¼•æ“å¯èƒ½éš¾ä»¥æ­£ç¡®è¯†åˆ«å­—ç¬¦ã€‚
<img width="1077" height="748" alt="image" src="https://github.com/user-attachments/assets/b0ec4ab1-b7f7-4f68-a072-6a4a2a9d2ad2" />

### å°†å›¾åƒè½¬æ¢ä¸ºç°åº¦ï¼šç°åº¦è½¬æ¢ç®€åŒ–äº† OCR å¤„ç†ï¼Œä½¿æ–‡æœ¬æ›´æ˜“äºæ£€æµ‹ã€‚
é¦–å…ˆï¼Œæˆ‘ä»¬åˆ é™¤é¢œè‰²ä¿¡æ¯ï¼Œå› ä¸º OCR åªéœ€è¦é»‘ç™½æ–‡æœ¬ã€‚
```
# Convert the image to grayscale
img = np.array(img)  # Convert PIL image to NumPy array
gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)

# Display the grayscale image
display(Image.fromarray(gray))
```
**ä¸ºä»€ä¹ˆé€‰æ‹©ç°åº¦ï¼Ÿ**
- å‡å°‘ä¸å¿…è¦çš„ç»†èŠ‚ã€‚
- å¸®åŠ© OCR ä¸“æ³¨äºå®é™…æ–‡æœ¬ï¼Œè€Œä¸æ˜¯é¢œè‰²æˆ–èƒŒæ™¯ã€‚
### ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼å¢å¼ºå¯¹æ¯”åº¦
æŸäº›æ‰«æçš„æ–‡æ¡£å…·æœ‰ä¸å‡åŒ€çš„å…‰çº¿æˆ–æ–‡æœ¬è¤ªè‰²ã€‚æ­¤æ­¥éª¤å¯æé«˜æ–‡æœ¬å¯è§æ€§ã€‚ä¸ºäº†ä½¿æ–‡æœ¬è„±é¢–è€Œå‡ºï¼Œæˆ‘ä»¬åº”ç”¨äº†è‡ªé€‚åº”é˜ˆå€¼ã€‚
```
# Apply adaptive thresholding to enhance contrast
gray = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)

# Display the processed image
display(Image.fromarray(gray))
```
**ä¸ºä»€ä¹ˆè¦å¢å¼ºå¯¹æ¯”åº¦ï¼Ÿ**
- ä½¿OCRçš„å¾®å¼±æ–‡æœ¬æ›´ç²—ã€‚
- å¤„ç†å…‰ç…§ä¸­çš„é˜´å½±å’Œå˜åŒ–ã€‚
 
### é€šè¿‡åŒè¾¹æ»¤æ³¢é™ä½å™ªå£°
OCRå¯èƒ½ä¼šå°†å™ªéŸ³è¯¯è®¤ä¸ºæ–‡æœ¬ï¼Œä»è€Œå¯¼è‡´é”™è¯¯ã€‚åŒè¾¹è¿‡æ»¤å¯å¹³æ»‘èƒŒæ™¯ï¼ŒåŒæ—¶ä¿æŒæ–‡æœ¬æ¸…æ™°ã€‚
```
# Apply Bilateral Filtering for noise reduction
gray = cv2.bilateralFilter(gray, 9, 75, 75)

# Display the processed image
display(Image.fromarray(gray))
```
**ä¸ºä»€ä¹ˆè¦é™å™ªï¼Ÿ**
- å»é™¤ OCR å¯èƒ½è¯¯è§£çš„ä¸éœ€è¦çš„æ–‘ç‚¹ã€‚
- ä¿æŒæ–‡æœ¬è¾¹ç¼˜æ¸…æ™°ï¼Œä½¿å­—ç¬¦ä¸ä¼šæ¨¡ç³Šã€‚
### è°ƒæ•´å›¾åƒå¤§å°ä»¥æé«˜OCRç²¾åº¦
å¦‚æœæ‰«æçš„æ–‡æœ¬å¤ªå°ï¼ŒOCRå¯èƒ½ä¼šé—æ¼ç»†èŠ‚ã€‚æˆ‘ä»¬æ”¾å¤§å›¾åƒä»¥æ”¹è¿›æ£€æµ‹ã€‚
```
# Resize image for better OCR accuracy
scale_percent = 200  # Increase image size by 200%
width = int(gray.shape[1] * scale_percent / 100)
height = int(gray.shape[0] * scale_percent / 100)
gray = cv2.resize(gray, (width, height), interpolation=cv2.INTER_CUBIC)

# Display the resized image
display(Image.fromarray(gray))
```
**ä¸ºä»€ä¹ˆè¦è°ƒæ•´å¤§å°ï¼Ÿ**
- æ”¾å¤§å°æ–‡æœ¬ï¼Œä»¥ä¾¿OCRå¯ä»¥æ›´å‡†ç¡®åœ°è¯†åˆ«å­—æ¯ã€‚
- é˜²æ­¢OCRè¯¯è¯»å¾®å°å­—ç¬¦ã€‚

##  ç¬¬ 6 æ­¥ï¼šå¯¹é¢„å¤„ç†å›¾åƒè¿è¡Œ OCR
ä½¿ç”¨ Tesseract OCR æå–æ–‡æœ¬ï¼ŒTesseract æä¾›äº†å¤šç§æ–‡æœ¬æå–é€‰é¡¹ï¼Œä½†å¯¹äºæ‰«ææ–‡æ¡£æ¥è¯´ï¼Œæœ€å¥½çš„æ–¹æ³•æ˜¯ä½¿ç”¨ä¼˜åŒ–çš„é…ç½®ã€‚
```
# Run OCR on the preprocessed image
custom_config = r'--oem 3 -l eng'
ocr_text = pytesseract.image_to_string(gray, config=custom_config)

# Print extracted text
print("OCR Extracted Text:\n")
print(ocr_text)
```
**-oem 3**: ä½¿ç”¨åŸºäºAIï¼ˆåŸºäºLSTMçš„æ¨¡å‹ï¼‰çš„æœ€ä½³OCRå¼•æ“ã€‚

**l eng**:æŒ‡å®šæ–‡æœ¬ä¸ºè‹±æ–‡ã€‚
å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œæˆ‘ä»¬åº”è¯¥ä¼šçœ‹åˆ°ä»æ‰«ææ–‡æ¡£ä¸­æå–çš„æ–‡æœ¬æ‰“å°åœ¨ç»ˆç«¯ä¸Šã€‚
ç„¶è€Œï¼ŒOCR å¹¶éå®Œç¾æ— ç¼ºâ€”â€”æœ‰æ—¶å®ƒä¼šè¯¯è¯»å­—ç¬¦ã€æ·»åŠ ç©ºæ ¼æˆ–æ¼æ‰å•è¯ã€‚

## ç¬¬7æ­¥: æ¸…ç† OCR è¾“å‡º
OCR æ–‡æœ¬ç»å¸¸åŒ…å«é”™è¯¯ã€ä¸å¿…è¦çš„ç©ºæ ¼æˆ–å¥‡æ€ªçš„æ ¼å¼ã€‚æˆ‘ä»¬éœ€è¦å¯¹å…¶è¿›è¡Œæ¸…ç†ï¼Œä½¿å…¶æ›´å…·å¯è¯»æ€§å’Œç»“æ„æ€§ã€‚
- Tesseract æœ‰æ—¶ä¼šå°†æ–‡æœ¬æ‹†åˆ†æˆå¤šè¡Œï¼Œä½†å®é™…ä¸Šå¹¶ä¸åº”è¯¥æ‹†åˆ†ã€‚è®©æˆ‘ä»¬æ¥ç§»é™¤è¿™äº›å¤šä½™çš„æ¢è¡Œç¬¦å’Œç©ºæ ¼ã€‚
```
# Remove excessive newlines and extra spaces
ocr_text = " ".join(ocr_text.split())
print("Cleaned OCR Text:\n", ocr_text)
```
**.split()** å°†æ–‡æœ¬åˆ†è§£ä¸ºå•è¯åˆ—è¡¨ã€‚

**" ".join(... )** å°†å•è¯ç”¨å•ä¸ªç©ºæ ¼é‡æ–°ç»„åˆåœ¨ä¸€èµ·ï¼Œåˆ é™¤å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œç¬¦ã€‚
- OCR æœ‰æ—¶ä¼šè¯¯è¯»å­—æ¯å’Œæ•°å­—ï¼ˆä¾‹å¦‚ï¼Œå°†â€œLOANâ€è¯¯è¯»ä¸ºâ€œL0ANâ€ï¼‰ã€‚è®©æˆ‘ä»¬ä½¿ç”¨æ–‡æœ¬æ›¿æ¢æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚
```
import re

# Fix common OCR errors
ocr_text = re.sub(r'\bL0AN\b', 'LOAN', ocr_text, flags=re.IGNORECASE)
ocr_text = re.sub(r'\bM0RTGAGE\b', 'MORTGAGE', ocr_text, flags=re.IGNORECASE)
ocr_text = re.sub(r'\b1NTEREST\b', 'INTEREST', ocr_text, flags=re.IGNORECASE)
ocr_text = re.sub(r'[^a-zA-Z0-9\s,.%-]', '', ocr_text)  # Remove unwanted symbols

print("Corrected OCR Text:\n", ocr_text)
```
æˆ‘ä»¬ç”¨å®ƒ**re.sub()** æ¥æŸ¥æ‰¾å¸¸è§çš„ OCR é”™è¯¯å¹¶ç”¨æ­£ç¡®çš„å•è¯æ›¿æ¢å®ƒä»¬ï¼š
"L0AN"â†’"LOAN"
"M0RTGAGE"â†’"MORTGAGE"
"1NTEREST"â†’"INTEREST"
## æ­¥éª¤8ï¼šæå–é‡è¦ä¿¡æ¯
ç°åœ¨æˆ‘ä»¬æœ‰äº†å¹²å‡€çš„æ–‡æœ¬ï¼Œè®©æˆ‘ä»¬æå–å…³é”®çš„è´¢åŠ¡ç»†èŠ‚ï¼Œå¦‚è´·æ¬¾é‡‘é¢ã€åˆ©ç‡æˆ–å€Ÿæ¬¾äººå§“åã€‚
 
ä½†æ˜¯æˆ‘ä»¬å¦‚ä½•æ‰¾åˆ°è¿™äº›é‡‘é¢å‘¢ï¼ŸOCR ä¸ä¼šå‘Šè¯‰æˆ‘ä»¬é‡è¦æ•°æ®åœ¨å“ªé‡Œâ€”â€”å®ƒåªä¼šè½¬å‚¨åŸå§‹æ–‡æœ¬ã€‚æˆ‘ä»¬å°†ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ **re.search()** åœ¨æ–‡æœ¬ä¸­æŸ¥æ‰¾è´·æ¬¾é‡‘é¢ã€‚
```
# Extract loan amount if present in the text
loan_match = re.search(r"Loan Amount[:\s$]*([\d,]+)", ocr_text, re.IGNORECASE)

if loan_match:
    loan_amount = loan_match.group(1)
    print(f"Extracted Loan Amount: ${loan_amount}")
```
- æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾â€œè´·æ¬¾é‡‘é¢â€åè·Ÿç¾å…ƒç¬¦å·æˆ–æ•°å­—ã€‚
-    å¦‚æœæ‰¾åˆ°ï¼Œæˆ‘ä»¬å°±æå–æ•°å€¼å¹¶æ‰“å°å®ƒã€‚

## æ­¥éª¤9ï¼šä»OCRè¾“å‡ºä¸­æå–è¾¹ç•Œæ¡†
åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»æå–å¹¶æ¸…ç†äº†æ–‡æœ¬ï¼Œä½†æˆ‘ä»¬è¿˜éœ€è¦è¯†åˆ«æ¯ä¸ªå•è¯åœ¨é¡µé¢ä¸Šå‡ºç°çš„ä½ç½®ã€‚
æˆ‘ä»¬å°†ä½¿ç”¨å®ƒpytesseract.image_to_data()æ¥æå–æ¯ä¸ªå•è¯åŠå…¶ä½ç½®ã€ç½®ä¿¡åº¦å’Œå…¶ä»– OCR å…ƒæ•°æ®ã€‚
```
# Extract bounding box data from OCR
ocr_data = pytesseract.image_to_data(gray, output_type=pytesseract.Output.DICT)

# Print first 5 extracted words with bounding boxes
for i in range(5):
    print(f"Word: {ocr_data['text'][i]}, BBox: ({ocr_data['left'][i]}, {ocr_data['top'][i]}, {ocr_data['width'][i]}, {ocr_data['height'][i]})")
pytesseract.image_to_data(gray, output_type=pytesseract.Output.DICT)
```
- è¿”å›åŒ…å«æ–‡æœ¬ä½ç½®çš„å­—å…¸ã€‚
- æˆ‘ä»¬æ‰“å°å‰ 5 ä¸ªå•è¯åŠå…¶è¾¹ç•Œæ¡†åæ ‡ã€‚
## æ­¥éª¤ 10ï¼šä¸º OCR æ£€æµ‹åˆ°çš„å•è¯ç»˜åˆ¶è¾¹ç•Œæ¡†
ç°åœ¨æˆ‘ä»¬æœ‰äº†è¾¹ç•Œæ¡†åæ ‡ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ OpenCV åœ¨æ£€æµ‹åˆ°çš„å•è¯å‘¨å›´ç»˜åˆ¶æ¡†ã€‚
åœ¨å›¾åƒä¸Šå¯è§†åŒ–æ£€æµ‹åˆ°çš„å•è¯
```
import cv2
from PIL import Image

# Convert image to OpenCV BGR format
img_bgr = cv2.cvtColor(gray, cv2.COLOR_RGB2BGR)

# Get OpenCV image height for correct y-coordinate transformation
page_height = gray.shape[0]

# Define confidence threshold (ignore low-confidence words)
confidence_threshold = 40

# ğŸ“Œ Step 9.1: Loop through Extracted OCR Words & Draw Bounding Boxes
for i in range(len(ocr_data["text"])):
    word = ocr_data["text"][i].strip()
    x, y, w, h = ocr_data["left"][i], ocr_data["top"][i], ocr_data["width"][i], ocr_data["height"][i]
    conf = int(ocr_data["conf"][i])  # Convert confidence to int

    # Ignore empty words & low-confidence OCR text
    if not word or conf < confidence_threshold:
        continue

    # Draw bounding box
    cv2.rectangle(img_bgr, (x, y), (x + w, y + h), (0, 255, 0), 2)
    cv2.putText(img_bgr, word, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

# ğŸ“Œ Step 9.2: Convert Back to RGB & Display the Image
img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
display(Image.fromarray(img_rgb))
``` 
## æ­¥éª¤ 11ï¼šè¯†åˆ«å¹¶çªå‡ºæ˜¾ç¤ºæ–‡æ¡£ä¸­çš„å…³é”®å­—æ®µ
ç°åœ¨æˆ‘ä»¬å·²ç»æˆåŠŸæå–å¹¶å¯è§†åŒ–äº†æ–‡æœ¬ï¼Œè®©æˆ‘ä»¬æ›´è¿›ä¸€æ­¥ã€‚
æˆ‘ä»¬ä¸ä¼šä¸ºæ‰€æœ‰æ£€æµ‹åˆ°çš„å•è¯ç»˜åˆ¶è¾¹ç•Œæ¡†ï¼Œè€Œæ˜¯ä»…çªå‡ºæ˜¾ç¤ºæŠµæŠ¼æ–‡ä»¶ä¸­é‡è¦çš„å…³é”®å­—æ®µã€‚
1. æŸ¥æ‰¾å¹¶çªå‡ºæ˜¾ç¤ºå…³é”®å­—æ®µ
æˆ‘ä»¬å°†æ‰«æ OCR æ–‡æœ¬ï¼Œæ‰¾åˆ°å…³é”®è¯ï¼Œå¹¶ä»…åœ¨å®ƒä»¬å‘¨å›´ç»˜åˆ¶è¾¹ç•Œæ¡†ã€‚
```
# Define key fields to highlight
key_fields = ["MORTGAGE", "NOTE", "LENDER", "PROPERTY ADDRESS", "DATE", "SIGNATURE"]

# Convert image to OpenCV BGR format
img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)

# Loop through extracted OCR words
for i in range(len(ocr_data["text"])):
    word = ocr_data["text"][i].strip().upper()  # Convert to uppercase for better matching
    x, y, w, h = ocr_data["left"][i], ocr_data["top"][i], ocr_data["width"][i], ocr_data["height"][i]

    if word in key_fields:  # Highlight only key fields found in the document
        cv2.rectangle(img_bgr, (x, y), (x + w, y + h), (0, 0, 255), 2)  # Red bounding box
        cv2.putText(img_bgr, word, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

# Convert back to RGB for display
img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
display(Image.fromarray(img_rgb))
``` 
- **key_fields** æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªæƒ³è¦çªå‡ºæ˜¾ç¤ºçš„é‡è¦å•è¯åˆ—è¡¨ï¼ˆ ï¼‰ã€‚
- æˆ‘ä»¬å¾ªç¯éå†æå–çš„ OCR å•è¯å¹¶æ£€æŸ¥å®ƒä»¬æ˜¯å¦ä¸ä»»ä½•å…³é”®å­—æ®µåŒ¹é…ã€‚
- å¦‚æœæ‰¾åˆ°åŒ¹é…é¡¹ï¼Œæˆ‘ä»¬å°†ï¼š
  -å›´ç»•è¯¥å•è¯ç»˜åˆ¶ä¸€ä¸ªçº¢è‰²çŸ©å½¢ã€‚
  -åœ¨å…¶ä¸Šæ–¹æ·»åŠ æ ‡ç­¾ï¼Œä»¥ä¾¿äºæŸ¥çœ‹ã€‚
- æˆ‘ä»¬æ˜¾ç¤ºçš„å›¾åƒä»…çªå‡ºæ˜¾ç¤ºå…³é”®å­—æ®µã€‚
